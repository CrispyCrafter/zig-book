---
engine: knitr
knitr: true
syntax-definition: "../Assets/zig.xml"
---


```{r}
#| include: false
source("../zig_engine.R")
knitr::opts_chunk$set(
    auto_main = FALSE,
    build_type = "lib"
)
```




# Introducing Vectors and SIMD

In this chapter, I'm going to discuss vectors in Zig, which are
related to SIMD operations. Before we dive into the subject, is worth
mentioning that vectors in Zig have no relationship with the `std::vector` class
from C++. Remember, as we discussed at @sec-dynamic-array,
dynamic/growable arrays in Zig are represented by the `std.ArrayList()` structure
from the Zig Standard Library.


## What is SIMD?

SIMD (*Single Instruction/Multiple Data*) is a group of operations that are widely used
on video/audio editing programs, and also in graphics applications. SIMD is not a new technology,
but the massive use of SIMD on normal desktop computers is somewhat recent. In the old days, SIMD
was only used on "supercomputers models".

Most modern CPU models (from AMD, Intel, etc.) these days (either in a desktop or in a
notebook model) have support for SIMD operations. If you have a very old CPU model installed in your
computer, then, is possible that you have no support for SIMD operations in your computer.

But why people have started using SIMD on their software? The answer is performance.
But what SIMD precisely do to achieve better performance? In essence, SIMD is a different
way to get parallel computing, and therefore, make faster calculations.

The basic idea behind SIMD is to have a single instruction that operates over multiple data
at the same time. When you perform a normal scalar operation, like for example, four add instructions,
each addition is performed separately, one after another. But with SIMD, these four add instructions
are translated into a single instruction, and, as consequence, the four additions are performed
in parallel, at the same time.


### Vectors

SIMD operations are performed over a special type of object, which are
called "vectors". A vector object is usually a fixed-sized block of 128 bits (16 bytes).
As consequence, most vector objects in the wild are arrays that contains 4 integer values (4 bytes each),
or, 4 floating point values (4 bytes each), or, 16 characters (1 byte each), etc.
However, different CPU models may have different extensions (or, "implementations") of SIMD,
which may offer more types of vector objects that are bigger in size (256 bits or 512 bits)
to accomodate more data into a single vector object.

You can create a new vector object in Zig by using the `@Vector()` built-in function. Inside this function,
you specify the vector length (number of elements in the vector), and the data type of the elements
of the vector. In the example below, I'm creating two vector objects (`v1` and `v2`) of 4 elements of type `u32` each.

Also notice in the example below, that a third vector object (`v3`) is created from the
sum of the previous two vector objects (`v1` plus `v2`). Therefore,
math operations over vector objects take place element-wise by default, because
the same operation (in this case, addition) is replicated in parallel, across
all elements of the vector.


```{zig}
#| auto_main: true
#| build_type: "run"
const v1 = @Vector(4, u32){4, 12, 37, 9};
const v2 = @Vector(4, u32){10, 22, 5, 12};
const v3 = v1 + v2;
try stdout.print("{any}\n", .{v3});
```

This is how SIMD creates more performance in our program. Instead of using a for or a while loop
to iterate through the elements of `v1` and `v2`, and adding them together, one element at a time,
we enjoy the benefits of SIMD, which performs all 4 additions in parallel, at the same time.

Therefore, the `@Vector` structure in Zig is essentially, the Zig representation of SIMD vector objects.
The elements on these vector objects will be operated in parallel, if, and only if your current CPU model
supports SIMD operation.



