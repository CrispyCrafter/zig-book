---
engine: knitr
knitr: true
syntax-definition: "../Assets/zig.xml"
---

```{r}
#| include: false
source("../zig_engine.R")
knitr::opts_chunk$set(
    auto_main = FALSE,
    build_type = "lib"
)
```



# Introducing threads and parallelism in Zig {#sec-thread}

Threads and parallelism is available in Zig through the `Thread` struct
from the Zig Standard Library. This struct represents a kernel thread, and it follows a POSIX Thread pattern,
meaning that, it works similar to a thread from the `pthread` library from the C Standard Library.

If you are not familiar with a thread, let's dive in first, before we show how a
thread is used in Zig.


## What are threads? {#sec-what-thread}

A thread is basically a separate context of execution.
We use threads to introduce parallelism into our program,
which in most cases, makes the program runs faster, because we have multiple tasks
being performed at the same time, parallel to each other.

Programs are normally single-threaded by default. Which means that each program
usually runs on a single thread, or, a single context of execution. When we have only one thread running, we have no
parallelism. And when we don't have parallelism, the commands are executed sequentially, that is,
only one command is executed at a time. By creating multiple threads inside our program,
we start to execute multiple tasks and commands at the same time.

Programs that create multiple threads are very commom on the wild. Because many different types
of applications are well suited for parallelism. Good examples are video and photo-editing applications
(e.g. Adobe Photoshop or DaVinci Resolve)
, games (e.g. The Witcher 3), and also web browsers (e.g. Google Chrome, Firefox, Microsoft Edge, etc).
For example, in web browsers, threads are normally used to implement tabs.
In other words, tabs in web browsers run as separate threads in the main process of
the web browser. Each new tab that you open in your web browser,
usually runs on a separate thread.

By running each tab in a separate thread, we allow all open tabs in the browser to run at the same time,
and independently from each other. For example, you might have YouTube, or Spotify, currently opened in
a tab, and you are listening to some podcast in that tab, while, at the same time,
you are working in another tab, writing an essay on Google Docs. Even if you are not looking
into the YouTube tab, you can still hear the podcast only because this YouTube tab is running in parallel
with the other tab where Google Docs is running.

Without threads, the other alternative would be to run each tab as a completely separate running
process in your computer. But that would be a bad choice, because just a few tabs would already consume
too much power and resources from your computer. Also, the chances of you experiencing lag and overhead
while using the browser would be high. Threads are faster to create, and they also consume
much, much less resources from the computer, specially because they share some resources
with the main process.

Therefore, is the use of threads in modern web browsers that allows you to hear the podcast
at the same time while you are writing something on Google Docs.
Without threads, a web browser would probably be limited to one single tab.

Threads are also good for anything that involves serving requests or orders.
Because serving a request takes time, and usually involves a lot of "waiting time".
In other words, we spend a lot of time in idle, waiting for something to complete.
For example, consider a restaurant. Serving orders in a restaurant usually involves
the following steps:

1. receive order from the client.
1. pass the order to the kitchen, and wait for the food to be cooked.
1. start cooking the food in the kitchen.
1. when the food is fully cooked deliver this food to the client.

If you think about the bulletpoints above, you will notice that one big moment of waiting
is present in this hole process, which is while the food is being prepared and cooked
inside the kitchen. Because while the food is being prepped, both the waiter and the client
itself are waiting for the food to be ready and delivered.

If we write a program to represent this restaurant, more specifically, a single-threaded program, then,
this program would be very inefficient. Because the program would stay in idle, waiting for a considerable amount
of time on the "check if food is ready" step.
Consider the code snippet exposed below that could potentially represent such
program.

The problem with this program is the while loop. This program will spend a lot of time
waiting on the while loop, doing nothing more than just checking if the food is ready.
This is waste of time. Instead of waiting for something to happen, the waiter
could just send the order to the kitchen, and just move on, and continue with receiving
more orders from other clients, and sending more orders to the kitchen.

```zig
const order = Order.init("Pizza Margherita", n = 1);
const waiter = Waiter.init();
waiter.receive_order(order)
waiter.ask_kitchen_to_cook();
var food_not_ready = false;
while (food_not_ready) {
    food_not_ready = waiter.is_food_ready();
}
const food = waiter.get_food_from_kitchen();
waiter.send_food_to_client(food);
```

This is why threads would be a great fit for this program. We could use threads
to free the waiters from their "waiting duties", so they can go on with their
other tasks, and receive more orders. Take a look at the next example, where I have re-written the above
program into a different program that uses threads to cook and deliver the orders.

You can see in this program that when a waiter receives a new order
from a client, this waiter executes the `send_order()` function.
The only thing that this function does is: it creates a new thread
and detaches it. Since creating a thread is a very fast operation,
this `send_order()` function returns almost immediatly,
so the waiter spends almost no time worring about the order, and just
move on and tries to get the next order from the clients.

Inside the new thread created, the order get's cooked by a chef, and when the
food is ready, it is delivered to the client's table.


```zig
fn cook_and_deliver_order(order: *Order) void {
    const chef = Chef.init()
    const food = chef.cook(order.*);
    chef.deliver_food(food);
}
fn send_order(order: Order) void {
    const cook_thread = Thread.spawn(
        .{}, cook_and_deliver_order, .{&order}
    );
    cook_thread.detach();
}

const waiter = Waiter.init()
while (true) {
    const order = waiter.get_new_order();
    if (order) {
        send_order(order);
    }
}
```



## Threads versus processes

When we run a program, this program is executed as a *process* in the operating system.
This is a one to one relationship, each program or application that you execute
is a separate process in the operating system. But each program, or each process,
can create and contain multiple threads inside of it. Therefore,
processes and threads have a one to many relationship.

This also means that every thread that we create is always associated with a particular process in our computer.
In other words, a thread is always a subset (or a children) of an existing process.
All threads share some of the resources associated with the process from which they were created.
And because threads share resources with the process, they are very good for making communication
between tasks easier.

For example, suppose that you were developing a big and complex application
that would be much simpler if you could split it in two, and make these two separate pieces talk
with each other. Some programmers opt to effectively write these two pieces of the codebase as two
completely separate programs, and then, they use IPC (*inter-process communication*) to make these
two separate programs/processes talk to each other, and make them work together.

However, some programmers find IPC hard to deal with, and, as consequence,
they prefer to write one piece of the codebase as the "main part of the program",
or, as the part of the code that runs as the process in the operating system,
while the other piece of the codebase is written as a task to be executed in
a new thread. A process and a thread can easily comunicate with each other
through both control flow, and also, through data, because they share and have
access to the same standard file descriptors (`stdout`, `stdin`, `stderr`) and also to the same memory space
on the heap.


In more details, each thread that you create have a separate stack frame reserved just for that thread,
which essentially means that each local object that you create inside this thread, is local to that
thread, i.e. the other threads cannot see this local object. Unless this object that you have created
is an object that lives on the heap. In other words, if the memory associated with this object
is on the heap, then, the other threads can potentially access this object.

Therefore, objects that are stored in the stack are local to the thread where they were created.
But objects that are stored on the heap are potentially accessible to other threads. All of this means that,
each thread have it's own separate stack frame, but, at the same time, all threads share
the same heap, the same standard file descriptors (which means that they share the same `stdout`, `stdin`, `stderr`),
and the same global data section in the program.



## Creating a thread

We create new threads in Zig, by first, importing the `Thread` struct into
our current Zig module, and then, calling the `spawn()` method of this struct,
which creates (or, "spawns") a new thread of execution from our current process.
This method have three arguments, which are, respectively:

1. a `SpawnConfig` object, which contains configurations for the spawn process.
1. the name of the function that is going to be executed (or, that is going to be "called") inside this new thread.
1. a list of arguments (or inputs) to be passed to the function provided in the second argument.

With these three arguments, you can control how the thread get's created, and also, specify which
work (or "tasks") will be performed inside this new thread. A thread is just a separate context of execution,
and we usually create new threads in our code, because we want to perform some work inside this
new context of execution. And we specify which exact work, or, which exact steps that are going to be
performed inside this context, by providing the name of a function on the second argument of the `spawn()` method.

Thus, when this new thread get's created, this function that you provided as input to the `spawn()`
method get's called, or, get's executed inside this new thread. You can control the
arguments, or, the inputs that are passed to this function when it get's called, by providing
a list of arguments (or a list of inputs) on the third argument of the `spawn()` method.
These arguments are passed to the function in the same order that they are
provided to `spawn()`.

Furthermore, the `SpawnConfig` is a struct object with only two possible fields, or, two possible members, that you
can set to tailor the spawn behaviour. These fields are:

- `stack_size`: you can provide an `usize` value to specify the size (in bytes) of the thread's stack frame. By default, this value is: $16 \times 1024 \times 1024$.
- `allocator`: you can provide an allocator object to be used when allocating memory for the thread.

To use one of these two fields (or, "configs") you just have to create a new object of type `SpawnConfig`,
and provide this object as input to the `spawn()` method. But, if you are not interested in using
one of these configs, and you are ok with using just the defaults, you can just provide an anonymous
struct literal (`.{}`) in the place of this `SpawnConfig` argument.

As our first, and very simple example, consider the code exposed below.
Inside the same program, you can create multiple threads of execution if you want to.
But, in this first example, we are creating just a single thread of execution, because
we call `spawn()` only once.

Also, notice in this example that we are executing the function `do_some_work()`
inside the new thread. Since this function receives no inputs, because it has
no arguments, in this instance, we have passed an empty list, or, more precisely, an empty and anonymous struct (`.{}`)
in the third argument of `spawn()`.


```{zig}
#| build_type: "run"
const std = @import("std");
const stdout = std.io.getStdOut().writer();
const Thread = std.Thread;
fn do_some_work() !void {
    _ = try stdout.write("Starting the work.\n");
    std.time.sleep(100 * std.time.ns_per_ms);
    _ = try stdout.write("Finishing the work.\n");
}

pub fn main() !void {
    const thread = try Thread.spawn(.{}, do_some_work, .{});
    thread.join();
}
```

Notice the use of `try` when calling the `spawn()` method. This means
that this method can return an error in some circunstances. One circunstance
in particular is when you attempt to create a new thread, when you have already
created too much (i.e. you have excedeed the quota of concurrent threads in your system).

But, if the new thread is succesfully created, the `spawn()` method returns a handler
object (which is just an object of type `Thread`) to this new thread. You can use
this handler object to effectively control all aspects of the thread.

The instant that you create the new thread, the function that you provided as input to `spawn()`
get's invoked (i.e. get's called) to start the execution on this new thread.
In other words, everytime you call `spawn()`, not only a new thread get's created,
but also, the "start work button" of this thread get's automatically pressed.
So the work being performed in this thread starts at the moment that the thread is created.
This is similar to how `pthread_create()` from the `pthreads` library in C works,
which also starts the execution at the moment that the thread get's created.


## Returning from a thread

We have learned on the previous section that the execution of the thread starts at the moment
that the thread get's created. Now, we will learn how to "join" or "detach" a thread in Zig.
"Join" and "detach" are operations that control how the thread returns to
the main thread, or, the main process in our program.

In essence, we perform these operations by using the methods `join()` and `detach()` from the thread handler object.
Every thread that you create can be marked as either *joinable* or *detached* [@linux_pthread_create].
You can turn a thread into a *detached* thread by calling the `detach()` method
from the thread handler object. But if you call the `join()` method instead, then, this thread
becomes a *joinable* thread.

A thread cannot be both *joinable* and *detached*. Which in general means
that you cannot call both `join()` and `detach()` on the same thread.
But a thread must be one of the two, meaning that, you should always call
either `join()` or `detach()` over a thread. If you don't call
one of these two methods over your thread, you introduce undefined behaviour into your program,
which is described at @sec-not-call-join-detach.

Now, let's describe what each of these two methods do to your thread.


### Joining a thread

When you join a thread, you are essentially saying: "Hey! Could you please wait for the thread to finish,
before you continue with your execution?". For example, if we comeback to our first and simpliest example
of a thread in Zig, in that example we have created a single thread inside the `main()` function of our program,
and just called `join()` over this thread at the end. This section of the code example is reproduced below.

Because we are joining this new thread inside the `main()`'s scope, it means that the
execution of `main()` is temporarily stopped, to wait for the execution of the thread
to finish. That is, the execution of `main()` stops temporarily at the line where `join()` get's called,
and it will continue only after the thread has finished it's tasks.

```{zig}
#| eval: false
pub fn main() !void {
    const thread = try Thread.spawn(.{}, do_some_work, .{});
    thread.join();
}
```

Because we have joined this new thread inside `main()`, by calling `join()`, we have a
garantee that this new thread will finish before the end of the execution of `main()`.
Because it is garanteed that `main()` will wait for the thread to finish it's tasks.
You could also interpret this as: the execution of main will hang at
the line where `join()` is called, and the next lines of code that come after
this `join()` call, will be executed solely after the execution of main
is "unlocked" after the thread finish it's tasks.

In the example above, there is no more expressions after the `join()` call. We just have the end
of the `main()`'s scope, and, therefore after the thread finish it's tasks, the execution
of our program just ends, since there is nothing more to do. But what if we had more stuff to do
after the join call?

To demonstrate this other possibility, consider the next example exposed
below. Here, we create a `print_id()` function, that just receives an id
as input, and prints it to `stdout`. In this example, we are creating two
new threads, one after another. Then, we join the first thread, then,
we wait for two hole seconds, then, at last, we join the second thread.

The idea behind this example is that the last `join()` call is executed
only after the first thread finish it's task (i.e. the first `join()` call),
and also, after the two seconds of delay. If you compile and run this
example, you will notice that most messages are quickly printed to `stdout`,
i.e. they appear almost instantly on your screen.
However, the last message ("Joining thread 2") takes aroung 2 seconds to appear
in the screen.


```zig
fn print_id(id: *const u8) !void {
    try stdout.print("Thread ID: {d}\n", .{id.*});
}

pub fn main() !void {
    const id1: u8 = 1;
    const id2: u8 = 2;
    const thread1 = try Thread.spawn(.{}, print_id, .{&id1});
    const thread2 = try Thread.spawn(.{}, print_id, .{&id2});

    _ = try stdout.write("Joining thread 1\n");
    thread1.join();
    std.time.sleep(2 * std.time.ns_per_s);
    _ = try stdout.write("Joining thread 2\n");
    thread2.join();
}
```

```
Thread ID: Joining thread 1
1
Thread ID: 2
Joining thread 2
```

This demonstrates that both threads finish their work (i.e. printing the IDs)
very fast, before the two seconds of delay end. Because of that, the last `join()` call
returns pretty much instantly. Because when this last `join()` call happens, the second
thread have already finished it's task.

Now, if you compile and run this example, you will also notice that, in some cases,
the messages get intertwined with each other. In other words, you might see
the message "Joining thread 1" inserted in the middle of the message "Thread 1",
or vice-versa. This happens because:

- the threads are executing basically at the same time as the main process of the program (i.e. the `main()` function).
- the threads share the same `stdout` from the main process of the program, which means that the messages that the threads produce are sent to exact same place as the messages produced by the main process.

Both of these points were described previously at @sec-what-thread.
So the messages might get intertwined because they are being produced and
sent to the same `stdout` roughly at the same time.
Anyway, when you call `join()` over a thread, the current process will wait
for the thread to finish before it continues, and, when the thread does finishs it's
task, the resources associated with this thread are automatically freed, and,
the current process continues with it's execution.


### Detaching a thread

When you detach a thread, by calling the `detach()` method, the thread is marked as *detached*.
When a *detached* thread terminates, its resources are automatically released back to the system without
the need for another thread to join with this terminated thread.

In other words, when you call `detach()` over a thread is like when your children becomes adults,
i.e. they become independent from you. A detached thread frees itself, and it does need to report the results back
to you, when the thread finishs it's task. Thus, you normally mark a thread as *detached*
when you don't need to use the return value of the thread, or, when you don't care about
when exactly the thread finishs it's job, i.e. the thread solves everything by itself.

Take the code example below. We create a new thread, detach it, and then, we just
print a final message before we end our program. We use the same `print_id()`
function that we have used over the previous examples.


```zig
fn print_id(id: *const u8) !void {
    try stdout.print("Thread ID: {d}\n", .{id.*});
}

pub fn main() !void {
    const id1: u8 = 1;
    const thread1 = try Thread.spawn(.{}, print_id, .{&id1});
    thread1.detach();
    _ = try stdout.write("Finish main\n");
}
```

```
Finish main
```

Now, if you look closely at the output of this code example, you will notice
that only the final message in main was printed to the console. The message
that was supposed to be printed by `print_id()` did not appear in the console.
Why? Is because the main process of our program has finished first,
before the thread was able to say anything.

And that is perfectly ok behaviour, because the thread was detached, so, it was
able to free itself, without the need of the main process.
If you ask main to sleep (or "wait") for some extra nanoseconds, before it ends, you will likely
see the message printed by `print_id()`, because in such circunstance you
give enough time for the thread to finish before the main process ends.


## Introducing thread pools

There is a very commom pattern with threads with is "thread pools". A thread pool is essentially a
set of threads, or, a "pool" of threads. Many programmers like very much to use a pool of threads,
instead of manually create a thread here and there.

People like using thread pools
especially because it makes easier to manage multiple threads at once.
Also, using thread pools might increase performance as well in your program,
especially if you are constantly creating threads in your program to perform short-lived tasks.
In these instances, thread pools might increase performance because you do not have be constantly
creating and destroying threads all the time.

The main idea behind a thread pool is to have a set of threads already created and ready to perform
tasks at all times. So, you create a set of threads at the moment that your program starts, and keep
these threads alive while your program runs. Each of these threads will be either performing a task, or,
waiting for a task to be assigned.

The Zig Standard Library offers a thread pool implementation on the `std.Thread.Pool` struct.



## Introducing mutexes


## Potential problems in threads

TODO: calling functions that might return an error inside threads (`try`)
TODO: talk about deadlocks
TODO: talk about race conditions
TODO: joining with a thread that has already been joined leads to undefined behaviour.
TODO: talk about zombie threads.


### Race conditions

Threads create parallelism. As consequence, they create certain amount of confusion and complexity,
because we get different tasks being performed at the same time. As consequence, depending on the
size, or, the complexity of your program, or the amount of threads created, it might be difficult
to track the tasks, and understand what is happening in a particular moment inside your program.

A hole set of problems emerge from parallelism and multi-threaded programming, which are usually
categorized as "race conditions". A race condition problem is any bug in your program that depends
on "who get's there first". In other words, in each execution of your program,
you get a different answer, because a different person, or, a different function, or, a different part of the code is finishing
its tasks (or it is reaching a location) first than the others.

```{zig}
#| eval: false
const std = @import("std");
const stdout = std.io.getStdOut().writer();
const Thread = std.Thread;
fn do_some_work(thread_id: *const u8) !void {
    _ = try stdout.print("Starting thread {d}.\n", .{thread_id.*});
    std.time.sleep(100 * std.time.ns_per_ms);
    _ = try stdout.print("Finishing thread {d}.\n", .{thread_id.*});
}

pub fn main() !void {
    const id1: u8 = 1;
    const id2: u8 = 2;
    const thread1 = try Thread.spawn(.{}, do_some_work, .{&id1});
    const thread2 = try Thread.spawn(.{}, do_some_work, .{&id2});
    thread1.join();
    thread2.join();
}
```

```
Starting thread 1.
Starting thread 2.
Finishing thread Finishing thread 2.
1.
```





### Not calling `join()` or `detach()` {#sec-not-call-join-detach}

When you do not call neither of these methods (`join()` or `detach()`), then, your thread does not have a
clear "return point". You could also interpret this as: "nobody is properly resposible for managing the thread".
In more details, when we don't establish if a thread is either *joinable* or *detached*,
nobody becomes responsible for dealing with the return value of this thread, and also,
nobody becomes responsible for clearing (or freeing) the resources associated with this thread.

You don't want to be in this situation, so remember to always use `join()` or `detach()`
on the threads that you create. When you don't use these methods, the execution of the thread
becomes completely independent from the execution of the main process in your program.
This means that the main process of your program might end before the thread finish it's job,
or vice-versa. The idea is that we have no idea of who is going to finish first. It
becomes a race condition problem.
In such case, we loose control over this thread, and it's resources are never freed
(i.e. you have leaked resources in the system).



## Yielding a thread

The `Thread` struct supports yielding through the `yield()` method.
Yielding a thread means that the execution of the thread is temporarily stopped,
and the thread comes back to the end of the queue of priority of the scheduler from
your operating system.

That is, when you yield a thread, you are essentially saying the following to your OS:
"Hey! Could you please stop executing this thread for now, and comeback to continue it later?".
You could also interpret this yield operation as: "Could you please deprioritize this thread,
to focus on doing other things instead?", i.e. you are rescheduling the execution of that thread for later.
So this yield operation is also a way for you
to stop a particular thread, so that you can work and prioritize other threads instead.

Is important to say that, yielding a thread is a "not so commom" thread operation these days.
In other words, not many programmers use yielding in production, simply because is hard to use
this operation and make it work properly, and also, there
are better alternatives. Most programmers prefer to use `join()` instead.
In fact, most of the times, when you see somebody using yield, they are using it to help them
debug race conditions in their applications, i.e. yield is used as a debug tool.

Anyway, if you want to yield a thread, just call the `yield()` method from it.

```zig
thread.yield();
```



## How to stop, cancel of kill a particular thread




