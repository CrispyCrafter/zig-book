{
  "hash": "190f3ddcd0ec16cef0b95ac8d90ae677",
  "result": {
    "engine": "knitr",
    "markdown": "---\nengine: knitr\nknitr: true\nsyntax-definition: \"../Assets/zig.xml\"\n---\n\n\n\n\n\n\n\n\n\n# Introducing threads and concurrency in Zig {#sec-thread}\n\nThreads and concurrency is available in Zig through the `Thread` struct\nfrom the Zig Standard Library. This struct represents a kernel thread, and it follows a POSIX Thread pattern,\nmeaning that, it works similar to a thread from the `pthread` library from the C Standard Library.\n\nIf you are not familiar with a thread, let's dive in first, before we show how a\nthread is used in Zig.\n\n\n## What are threads? {#sec-what-thread}\n\nEach thread that you create have a separate stack frame reserved just for that thread,\nwhich essentially means that each local object that you create inside this thread, is local to that\nthread, i.e. the other threads cannot see this local object. Unless this object that you have created\nis an object that lives on the heap. In other words, if the memory associated with this object\nis on the heap, then, the other threads can potentially access this object.\n\nTherefore, objects that are stored in the stack are local to the thread where they were created.\nBut objects that are stored on the heap are accessible to other threads. All of this means that,\neach thread have it's own separate stack frame, but, at the same time, all threads share\nthe same heap, the same standard file descriptors (which means that they share the same `stdout`, `stdin`, `stderr`),\nand the same global data section in the program.\n\nThreads create concurrency. In other words, they create certain amount of confusion and complexity,\nbecause we get different tasks being performed at the same time. As consequence, depending on the\nsize, or, the complexity of your program, or the amount of threads created, it might be difficult\nto track the tasks, and understand what is happening in a particular moment inside your program.\n\nA hole set of problems emerge from concurrency and multi-threaded programming, which are usually\ncategorized as \"race conditions\". A race condition problem is any bug in your program that depends\non \"who get's there first\". In other words, in each execution of your program,\nyou get a different answer, because a different person, or, a different function, or, a different part of the code is finishing\nits tasks (or it is reaching a location) first than the others.\n\n\n\n\n\n::: {.cell}\n\n```{.zig .cell-code}\nconst std = @import(\"std\");\nconst stdout = std.io.getStdOut().writer();\nconst Thread = std.Thread;\nfn do_some_work(thread_id: *const u8) !void {\n    _ = try stdout.print(\"Starting thread {d}.\\n\", .{thread_id.*});\n    std.time.sleep(100 * std.time.ns_per_ms);\n    _ = try stdout.print(\"Finishing thread {d}.\\n\", .{thread_id.*});\n}\n\npub fn main() !void {\n    const id1: u8 = 1;\n    const id2: u8 = 2;\n    const thread1 = try Thread.spawn(.{}, do_some_work, .{&id1});\n    const thread2 = try Thread.spawn(.{}, do_some_work, .{&id2});\n    thread1.join();\n    thread2.join();\n}\n```\n:::\n\n\n\n\n\n```\nStarting thread 1.\nStarting thread 2.\nFinishing thread Finishing thread 2.\n1.\n```\n\n\n\n\n## Creating a thread\n\nWe create new threads in Zig, by first, importing the `Thread` struct into\nour current Zig module, and then, calling the `spawn()` method of this struct,\nwhich creates (or, \"spawns\") a new thread of execution.\nThis method have three arguments, which are, respectively:\n\n1. a `SpawnConfig` object, which contains configurations for the spawn process.\n1. the name of the function that is going to be executed (or, that is going to be \"called\") in this new thread.\n1. a list of arguments (or inputs) to be passed to the function provided in the second argument.\n\nWith these three arguments, you can control how the thread get's created, and also, specify which\nwork will be performed (or executed) inside this new thread. A thread is just a separate context of execution,\nand we usually create new threads in our code, because we want to perform some work inside this\nnew context of execution. And we specify which exact work, or, which exact steps that are going to be\nperformed inside this context, by providing the name of a function on the second argument of the `spawn()` method.\n\nThus, when this new thread get's created, this function that you provided as input to the `spawn()`\nmethod get's called, or, get's executed inside this new thread. You can control the\narguments, or, the inputs that are passed to this function when it get's called, by providing\na list of arguments (or a list of inputs) on the third argument of the `spawn()` method.\nThese arguments are passed to the function in the same order that they are\nprovided to `spawn()`.\n\nFurthermore, the `SpawnConfig` is a struct object with only two possible fields, or, two possible members, that you\ncan set to tailor the spawn behaviour. These fields are:\n\n- `stack_size`: you can provide an `usize` value to specify the size (in bytes) of the thread's stack frame. By default, this value is: $16 \\times 1024 \\times 1024$.\n- `allocator`: you can provide an allocator object to be used when allocating memory for the thread.\n\nTo use one of these two fields (or, \"configs\") you just have to create a new object of type `SpawnConfig`,\nand provide this object as input to the `spawn()` method. But, if you are not interested in using\none of these configs, and you are ok with using just the defaults, you can just provide a anonymous\nstruct literal (`.{}`) in the place of this `SpawnConfig` argument.\n\nAs our first, and very simple example, consider the code exposed below.\nInside the same program, you can create multiple threads of execution if you want to.\nBut, in this first example, we are creating just a single thread of execution, because\nwe call `spawn()` only once.\n\nAlso, notice in this example that we are executing the function `do_some_work()`\ninside the new thread. Since this function receives no inputs, because it has\nno arguments, in this instance, we have passed an empty list, or, more precisely, an empty and anonymous struct (`.{}`)\nin the third argument of `spawn()`.\n\n\n\n\n\n\n::: {.cell}\n\n```{.zig .cell-code}\nconst std = @import(\"std\");\nconst stdout = std.io.getStdOut().writer();\nconst Thread = std.Thread;\nfn do_some_work() !void {\n    _ = try stdout.write(\"Starting the work.\\n\");\n    std.time.sleep(100 * std.time.ns_per_ms);\n    _ = try stdout.write(\"Finishing the work.\\n\");\n}\n\npub fn main() !void {\n    const thread = try Thread.spawn(.{}, do_some_work, .{});\n    thread.join();\n}\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStarting the work.Finishing the work.\n```\n\n\n:::\n:::\n\n\n\n\n\nNotice the use of `try` when calling the `spawn()` method. This means\nthat this method can return an error in some circunstances. One circunstance\nin particular is when you attempt to create a new thread, when you have already\ncreated too much (i.e. you have excedeed the quota of concurrent threads in your system).\n\nIf the new thread is succesfully created, the `spawn()` method returns a handler\nobject (which is just an object of type `Thread`) to this new thread. You can use\nthis handler object to effectively control all aspects of the thread.\n\nThe instant that you create the new thread, the function that you provided as input to `spawn()`\nget's invoked (i.e. get's called) to start the execution on this new thread.\nIn other words, everytime you call `spawn()`, not only a new thread get's created,\nbut also, the \"start work button\" of this thread get's automatically pressed.\nSo the work being performed in this thread starts at the moment that the thread is created.\nThis is similar to how `pthread_create()` from the `pthreads` library in C works,\nwhich also starts the execution at the moment that the thread get's created.\n\n\n## Returning from a thread\n\nWe have learned on the previous section that the execution of the thread starts at the moment\nthat the thread get's created. Now, we will learn how to \"join\" or \"detach\" a thread in Zig.\n\"Join\" and \"detach\" are operations that control how the thread returns to\nthe main thread, or, the main process in our program.\n\nIn essence, we perform these operations by using the methods `join()` and `detach()` from the thread handler object.\nEvery thread that you create can be marked as either *joinable* or *detached* [@linux_pthread_create].\nYou can turn a thread into a *detached* thread by calling the `detach()` method\nfrom the thread handler object. But if you call the `join()` method instead, then, this thread\nbecomes a *joinable* thread.\n\nA thread cannot be both *joinable* and *detached*. Which in general means\nthat you cannot call both `join()` and `detach()` on the same thread.\nBut a thread must be one of the two, meaning that, you should always call\neither `join()` or `detach()` over a thread. If you don't call\none of these two methods over your thread, you introduce undefined behaviour into your program,\nwhich is described at @sec-not-call-join-detach.\n\nNow, let's describe what each of these two methods do to your thread.\n\n\n### Joining a thread\n\nWhen you join a thread, you are essentially saying: \"Hey! Could you please wait for the thread to finish,\nbefore you continue with your execution?\". For example, if we comeback to our first and simpliest example\nof a thread in Zig, in that example we have created a single thread inside the `main()` function of our program,\nand just called `join()` over this thread at the end. This section of the code example is reproduced below.\n\nBecause we are joining this new thread inside the `main()`'s scope, it means that the\nexecution of `main()` is temporarily stopped, to wait for the execution of the thread\nto finish. That is, the execution of `main()` will continue only after the thread has finished\nit's tasks.\n\n\n\n\n\n::: {.cell}\n\n```{.zig .cell-code}\npub fn main() !void {\n    const thread = try Thread.spawn(.{}, do_some_work, .{});\n    thread.join();\n}\n```\n:::\n\n\n\n\n\nIn other words, because we have joined this new thread inside `main()`, by calling `join()`, we have a\ngarantee that this new thread will finish before the end of the execution of `main()`.\nBecause it is garanteed that `main()` will wait for the thread to finish it's tasks.\n\nYou could also interpret this as: the execution of main will hang at\nthe line where `join()` is called, and the next lines of code that come after\nthis `join()` call, will be executed solely after the execution of main\nis \"unlocked\" after the thread finish it's tasks.\n\nIn the example above, there is no more expressions after the `join()` call. We just have the end\nof the `main()`'s scope, and, therefore after the thread finish it's tasks, the execution\nof our program just ends, since there is nothing more to do. But what if we had more stuff to do\nafter the join call?\n\nTo demonstrate this other possibility, consider the next example exposed\nbelow. Here, we create a `print_id()` function, that just receives an id\nas input, and prints it to `stdout`. In this example, we are creating two\nnew threads, one after another. Then, we join the first thread, then,\nwe wait for two hole seconds, then, at last, we join the second thread.\n\nThe idea behind this example is that the last `join()` call is executed\nonly after the first thread finish it's task (i.e. the first `join()` call),\nand also, after the two seconds of delay. If you compile and run this\nexample, you will notice that most messages are quickly printed to `stdout`,\ni.e. they appear almost instantly on your screen.\nHowever, the last message (\"Joining thread 2\") takes aroung 2 seconds to appear\nin the screen.\n\n\n```zig\nfn print_id(id: *const u8) !void {\n    try stdout.print(\"Thread ID: {d}\\n\", .{id.*});\n}\n\npub fn main() !void {\n    const id1: u8 = 1;\n    const id2: u8 = 2;\n    const thread1 = try Thread.spawn(.{}, print_id, .{&id1});\n    const thread2 = try Thread.spawn(.{}, print_id, .{&id2});\n\n    _ = try stdout.write(\"Joining thread 1\\n\");\n    thread1.join();\n    std.time.sleep(2 * std.time.ns_per_s);\n    _ = try stdout.write(\"Joining thread 2\\n\");\n    thread2.join();\n}\n```\n\n```\nThread ID: Joining thread 1\n1\nThread ID: 2\nJoining thread 2\n```\n\nThis demonstrates that both threads finish their work (i.e. printing the IDs)\nvery fast, before the two seconds of delay end. Because of that, the last `join()` call\nreturns pretty much instantly. Because when this last `join()` call happens, the second\nthread have already finished it's task.\n\nNow, if you compile and run this example, you will also notice that, in some cases,\nthe messages get intertwined with each other. In other words, you might see\nthe message \"Joining thread 1\" inserted in the middle of the message \"Thread 1\",\nor vice-versa. This happens because:\n\n- the threads are executing basically at the same time as the main process of the program (i.e. the `main()` function).\n- the threads share the same `stdout` from the main process of the program, which means that the messages that the threads produce are sent to exact same place as the messages produced by the main process.\n\nBoth of these points were previously at @sec-what-thread.\nAnyway, when you call `join()` over a thread, the current process will wait\nfor the thread to finish before it continues, and, when the thread does finishs it's\ntask, the resources associated with this thread are automatically freed, and,\nthe current process continues with it's execution.\n\n\n### Detaching a thread\n\nWhen you detach a thread, by calling the `detach()` method, the thread is marked as *detached*.\nWhen a *detached* thread terminates, its resources are automatically released back to the system without\nthe need for another thread to join with this terminated thread.\n\nIn other words, when you call `detach()` over a thread is like when your children becomes adults,\ni.e. they become independent from you. A detached thread frees itself, and it does need to report the results back\nto you, when the thread finishs it's task. Thus, you normally mark a thread as *detached*\nwhen you don't need to use the return value of the thread, or, when you don't care about\nwhen exactly the thread finishs it's job, i.e. the thread solves everything by itself.\n\nTake the code example below. We create a new thread, detach it, and then, we just\nprint a final message before we end our program. We use the same `print_id()`\nfunction that we have used over the previous examples.\n\n\n```zig\nfn print_id(id: *const u8) !void {\n    try stdout.print(\"Thread ID: {d}\\n\", .{id.*});\n}\n\npub fn main() !void {\n    const id1: u8 = 1;\n    const thread1 = try Thread.spawn(.{}, print_id, .{&id1});\n    thread1.detach();\n    _ = try stdout.write(\"Finish main\\n\");\n}\n```\n\n```\nFinish main\n```\n\nNow, if you look closely at the output of this code example, you will notice\nthat only the final message in main was printed to the console. The message\nthat was supposed to be printed by `print_id()` did not appear in the console.\nWhy? Is because the main process of our program has finished first,\nbefore the thread was able to say anything.\n\nAnd that is perfectly ok behaviour, because the thread was detached, so, it was\nable to free itself, without the need of the main process.\nIf ask main to sleep (or \"wait\") for some nanoseconds, before it ends, you will likely\nsee the message printed by `print_id()`, because in such circunstance you\ngive more time for the thread to finish before the main process ends.\n\n\n## Yielding a thread\n\nYou can yield a thread in Zig by calling the `yield()` method from the thread handler object.\nYielding a thread means that the execution of the thread is temporarily paused,\nand the thread humbly asks the scheduler of your system to move the thread back into\nthe end of the queue of priority.\n\nEvery thread that you create is registered into a queue of priority that is controlled\nby the scheduler of your system. When you yield a thread, the thread is essentially allowing\nfor other threads to run.\nHaving sad that, is important to emphasize that yielding a thread is rarely used.\nMost programmers prefer to never use it,\nbecause there are better options to use then yielding, specially `join()`,\nand also, signals and mutexes.\n\n\n\n\n## Potential problems in threads\n\nTODO: calling functions that might return an error inside threads (`try`)\nTODO: talk about deadlocks\nTODO: talk about race conditions\nTODO: joining with a thread that has already been joined leads to undefined behaviour.\nTODO: talk about zombie threads.\n\n### Not calling `join()` or `detach()` {#sec-not-call-join-detach}\n\nWhen you do not call neither of these methods (`join()` or `detach()`), then, your thread does not have a\nclear \"return point\". You could also interpret this as: \"nobody is properly resposible for managing the thread\".\nIn more details, when we don't establish if a thread is either *joinable* or *detached*,\nnobody becomes responsible for dealing with the return value of this thread, and also,\nnobody becomes responsible for clearing (or freeing) the resources associated with this thread.\n\nYou don't want to be in this situation, so remember to always use `join()` or `detach()`\non the threads that you create. When you don't use these methods, the execution of the thread\nbecomes completely independent from the execution of the main process in your program.\nThis means that the main process of your program might end before the thread finish it's job,\nor vice-versa. The idea is that we have no idea of who is going to finish first. It\nbecomes a race condition problem.\nIn such case, we loose control over this thread, and it's resources are never freed\n(i.e. you have leaked resources in the system).\n\n\n\n## How to stop, cancel of kill a particular thread\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}