[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "An Introduction to Zig",
    "section": "",
    "text": "Preface\nIntro to zig:\nconst std = @import(\"std\");\n\npub fn main() !void {\n    const stdout = std.io.getStdOut().writer();\n    try stdout.print(\"Hello, {s}!\\n\", .{\"world\"});\n}\n\nHello, world!",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#book-metadata",
    "href": "index.html#book-metadata",
    "title": "An Introduction to Zig",
    "section": "Book metadata",
    "text": "Book metadata\nThis book was compiled using the following versions of Zig and Quarto:\n\nSystem version: Linux, 6.5.0-35-generic, 22.04.1-Ubuntu, x86_64.\nZig version: 0.13.0-dev.266+0b0625ccf.\nQuarto version: 1.4.549.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "Chapters/01-zig-weird.html",
    "href": "Chapters/01-zig-weird.html",
    "title": "1  Zig specific attributes",
    "section": "",
    "text": "1.1 How strings work in Zig?\nThe first project that we are going to build and discuss in this book is a base64 encoder/decoder. But in order for us to build such a thing, we need to get a better understanding on how strings work in Zig. So let’s discuss this specific aspect of Zig.\nIn Zig, a string literal (or a string object if you prefer) is a pointer to a null-terminated array of bytes. Each byte in this array is represented by an u8 value, which is an unsigned 8 bit integer, so, it is equivalent to the C data type unsigned char.\nZig always assumes that this sequence of bytes is UTF-8 encoded. This might not be true for every sequence of bytes you have it, but is not really Zig’s job to fix the encoding of your strings (you can use iconv1 for that). Today, most of the text in our modern world, specially on the web, should be UTF-8 encoded. So if your string literal is not UTF-8 encoded, then, you will likely have problems in Zig.\nLet’s take for example the word “Hello”. In UTF-8, this sequence of characters (H, e, l, l, o) is represented by the sequence of decimal numbers 72, 101, 108, 108, 111. In xecadecimal, this sequence is 0x48, 0x65, 0x6C, 0x6C, 0x6F. So if I take this sequence of hexadecimal values, and ask Zig to print this sequence of bytes as a sequence of characters (i.e. a string), then, the text “Hello” will be printed into the terminal:\nconst std = @import(\"std\");\nconst stdout = std.io.getStdOut().writer();\npub fn main() !void {\n    const bytes = [_]u8{0x48, 0x65, 0x6C, 0x6C, 0x6F};\n    try stdout.print(\"{s}\\n\", .{bytes});\n}\n\nHello\nIf you want to see the actual bytes that represents a string in Zig, you can use a for loop to iterate trough each byte in the string, and ask Zig to print each byte as an hexadecimal value to the terminal. You do that by using a print() statement with the X formatting specifier, like you would normally do with the printf() function2 in C.\nconst std = @import(\"std\");\nconst stdout = std.io.getStdOut().writer();\npub fn main() !void {\n    const string_literal = \"This is an example of string literal in Zig\";\n    try stdout.print(\"Bytes that represents the string object: \", .{});\n    for (string_literal) |byte| {\n        try stdout.print(\"{X} \", .{byte});\n    }\n    try stdout.print(\"\\n\", .{});\n}\n\nBytes that represents the string object: 54 68 69 \n   73 20 69 73 20 61 6E 20 65 78 61 6D 70 6C 65 20 6F\n  F 66 20 73 74 72 69 6E 67 20 6C 69 74 65 72 61 6C 2\n  20 69 6E 20 5A 69 67",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Zig specific attributes</span>"
    ]
  },
  {
    "objectID": "Chapters/01-zig-weird.html#how-strings-work-in-zig",
    "href": "Chapters/01-zig-weird.html#how-strings-work-in-zig",
    "title": "1  Zig specific attributes",
    "section": "",
    "text": "1.1.1 Strings in C\nAt first glance, this looks very similar to how C treats strings as well. That is, string values in C are also treated internally as an array of bytes, and this array is also null-terminated.\nBut one key difference between a Zig string and a C string, is that Zig also stores the length of the array inside the string object. This small detail makes your code safer, because is much easier for the Zig compiler to check if you are trying to access an element that is “out of bounds”, i.e. if your trying to access memory that does not belong to you.\nTo achieve this same kind of safety in C, you have to do a lot of work that kind of seems pointless. So getting this kind of safety is not automatic and much harder to do in C. For example, if you want to track the length of your string troughout your program in C, then, you first need to loop through the array of bytes that represents this string, and find the null element ('\\0') position to discover where exactly the array ends, or, in other words, to find how much elements the array of bytes contain.\nTo do that, you would need something like this in C. In this example, the C string stored in the object array is 25 bytes long:\n#include &lt;stdio.h&gt;\nint main() {\n    char* array = \"An example of string in C\";\n    int index = 0;\n    while (1) {\n        if (array[index] == '\\0') {\n            break;\n        }\n        index++;\n    }\n    printf(\"Number of elements in the array: %d\\n\", index);\n}\nNumber of elements in the array: 25\nBut in Zig, you do not have to do this, because the object already contains a len field which stores the length information of the array. As an example, the string_literal object below is 43 bytes long:\n\nconst std = @import(\"std\");\nconst stdout = std.io.getStdOut().writer();\npub fn main() !void {\n    const string_literal = \"This is an example of string literal in Zig\";\n    try stdout.print(\"{d}\\n\", .{string_literal.len});\n}\n\n43\n\n\n1.1.2 A better look at the object type\nNow, we can inspect better the type of objects that Zig create. To check the type of any object in Zig, you can use the @TypeOf() function. If we look at the type of the simple_array object below, you will find that this object is a array of 4 elements. Each element is a signed integer of 32 bits which corresponds to the data type i32 in Zig. That is what an object of type [4]i32 is.\nBut if we look closely at the type of the string_literal object below, you will find that this object is a constant pointer (hence the *const annotation) to an array of 43 elements (or 43 bytes). Each element is a single byte (more precisely, an unsigned 8 bit integer - u8), that is why we have the [43:0]u8 portion of the type below. In other words, the string stored inside the string_literal object is 43 bytes long. That is why you have the type *const [43:0]u8 below.\nIn the case of string_literal, it is a constant pointer (*const) because the object string_literal is declared as constant in the source code (in the line const string_literal = ...). So, if we changed that for some reason, if we declare string_literal as a variable object (i.e. var string_literal = ...), then, string_literal would be just a normal pointer to an array of unsigned 8-bit integers (i.e. * [43:0]u8).\nNow, if we create an pointer to the simple_array object, then, we get a constant pointer to an array of 4 elements (*const [4]i32), which is very similar to the type of the string_literal object. This demonstrates that a string object (or a string literal) in Zig is already a pointer to an array.\nJust remember that a “pointer to an array” is different than an “array”. So a string object in Zig is a pointer to an array of bytes, and not simply an array of bytes.\n\nconst std = @import(\"std\");\nconst stdout = std.io.getStdOut().writer();\npub fn main() !void {\n    const string_literal = \"This is an example of string literal in Zig\";\n    const simple_array = [_]i32{1, 2, 3, 4};\n    try stdout.print(\"Type of array object: {}\", .{@TypeOf(simple_array)});\n    try stdout.print(\n        \"Type of string object: {}\",\n        .{@TypeOf(string_literal)}\n    );\n    try stdout.print(\n        \"Type of a pointer that points to the array object: {}\",\n        .{@TypeOf(&simple_array)}\n    );\n}\n\nType of array object: [4]i32\nType of string object: *const [43:0]u8\nType of a pointer that points to the array object: *const [4]i32\n\n\n1.1.3 Byte vs unicode points\nIs important to point out that each byte in the array is not necessarily a single character. This fact arises from the difference between a single byte and a single unicode point.\nThe encoding UTF-8 works by assigning a number (which is called a unicode point) to each character in the string. For example, the character “H” is stored in UTF-8 as the decimal number 72. This means that the number 72 is the unicode point for the character “H”. Each possible character that can appear in a UTF-8 encoded string have its own unicode point.\nFor example, the Latin Capital Letter A With Stroke (Ⱥ) is represented by the number (or the unicode point) 570. However, this decimal number (570) is higher than the maximum number stored inside a single byte, which is 255. In other words, the maximum decimal number that can be represented with a single byte is 255. That is why, the unicode point 570 is actually stored inside the computer’s memory as the bytes C8 BA.\n\nconst std = @import(\"std\");\nconst stdout = std.io.getStdOut().writer();\npub fn main() !void {\n    const string_literal = \"Ⱥ\";\n    try stdout.print(\"Bytes that represents the string object: \", .{});\n    for (string_literal) |char| {\n        try stdout.print(\"{X} \", .{char});\n    }\n}\n\nBytes that represents the string object: C8 BA\nThis means that to store the character Ⱥ in an UTF-8 encoded string, we need to use two bytes together to represent the number 570. That is why the relationship between bytes and unicode points is not always 1 to 1. Each unicode point is a single character in the string, but not always a single byte corresponds to a single unicode point.\nAll of this means that if you loop trough the elements of a string in Zig, you will be looping through the bytes that represents that string, and not through the characters of that string. In the Ⱥ example above, the for loop needed two iterations (instead of a single iteration) to print the two bytes that represents this Ⱥ letter.\nNow, all english letters (or ASCII letters if you prefer) can be represented by a single byte in UTF-8. As a consequence, if your UTF-8 string contains only english letters (or ASCII letters), then, you are lucky. Because the number of bytes will be equal to the number of characters in that string. In other words, in this specific situation, the relationship between bytes and unicode points is 1 to 1.\nBut on the other side, if your string contains other types of letters… for example, you might be working with text data that contains, chinese, japanese or latin letters, then, the number of bytes necessary to represent your UTF-8 string will likely be much higher than the number of characters in that string.\nIf you need to iterate through the characters of a string, instead of its bytes, then, you can use the std.unicode.Utf8View struct to create an iterator that iterates through the unicode points of your string.\nIn the example below, we loop through the japanese characters “アメリカ”. Each of the four characters in this string is represented by three bytes. But the for loop iterates four times, one iteration for each character/unicode point in this string:\n\nconst std = @import(\"std\");\nconst stdout = std.io.getStdOut().writer();\npub fn main() !void {\n    var utf8 = (\n        (try std.unicode.Utf8View.init(\"アメリカ\"))\n            .iterator()\n    );\n    while (utf8.nextCodepointSlice()) |codepoint| {\n        try stdout.print(\n            \"got codepoint {}\\n\",\n            .{std.fmt.fmtSliceHexUpper(codepoint)}\n        );\n    }\n}\n\ngot codepoint E382A2\ngot codepoint E383A1\ngot codepoint E383AA\ngot codepoint E382AB",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Zig specific attributes</span>"
    ]
  },
  {
    "objectID": "Chapters/01-zig-weird.html#footnotes",
    "href": "Chapters/01-zig-weird.html#footnotes",
    "title": "1  Zig specific attributes",
    "section": "",
    "text": "https://www.gnu.org/software/libiconv/↩︎\nhttps://cplusplus.com/reference/cstdio/printf/↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Zig specific attributes</span>"
    ]
  },
  {
    "objectID": "Chapters/01-base64.html",
    "href": "Chapters/01-base64.html",
    "title": "2  Building a base64 encoder/decoder",
    "section": "",
    "text": "2.1 How the base64 algorithm work?\nNow, how exactly the algorithm behind the base64 encoding works? Let’s discuss that. First, I will explain the base64 scale, which is the scale of 64 characters that represents the base64 encoding system.\nAfter that, I explain the algorithm behind a base64 encoder, which is the part of the algorithm that is responsible for encoding messages into the base64 encoding system. Then, after that, I explain the algorithm behind a base64 decoder, which is the part of the algorithm that is responsible for translating base64 messages back into their original meaning.\nIf you are unsure about the differences between an “encoder” and a “decoder”, take a look at Section 2.2.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Building a base64 encoder/decoder</span>"
    ]
  },
  {
    "objectID": "Chapters/01-base64.html#how-the-base64-algorithm-work",
    "href": "Chapters/01-base64.html#how-the-base64-algorithm-work",
    "title": "2  Building a base64 encoder/decoder",
    "section": "",
    "text": "2.1.1 The base64 scale\nIn essence, the base64 encoding system is based on a scale that goes from 0 to 64 (hence the name). Each index in this scale is represented by a character (it is a scale of 64 characters). So, in order to convert some binary data, to the base64 encoding, we need to convert each binary number to the corresponding character in this “scale of 64 characters”.\nThe base64 scale starts with all ASCII uppercase letters (A to Z) which represents the first 25 indexes in this scale (0 to 25). After that, we have all ASCII lowercase letters (a to z), which represents the range 26 to 51 in the scale. After that, we have the one digit numbers (0 to 9), which represents the indexes from 52 to 61 in the scale. Finally, the last two indexes in the scale (62 and 63) are represented by the characters + and /, respectively.\nThese are the 64 characters that compose the base64 scale. The equal sign character (=) is not part of the scale itself, but it is a special character in the base64 encoding system. This character is used solely as a suffix, to mark the end of the character sequence, or, to mark the end of meaningful characters in the sequence.\nThe bulletpoints below summarises the base64 scale:\n\nrange 0 to 25 is represented by: ASCII uppercase letters -&gt; [A-Z];\nrange 26 to 51 is represented by: ASCII lowercase letters -&gt; [a-z];\nrange 52 to 61 is represented by: one digit numbers -&gt; [0-9];\nindex 62 and 63 are represented by the characters + and /, respectively;\nthe character = represents the end of meaningful characters in the sequence;\n\nEverytime that the base64 algorithm needs to fill some gap (which always occur at the end of the input string) with a group of 6 bits filled with only zeros (000000), this group is automatically mapped to the character =. Because this group of 6 bits is meaningless, they represent nothing, they are just filling the gap. As a result, the base64 algorithm maps this meaningless group to the character =, which represents the end of meaningful characters in the sequence. This characteristic is explained in more details at Section 2.1.3.\n\n\n2.1.2 Creating the scale as a lookup table\nThe best way to represent this scale in code, is to represent it as a lookup table. Lookup tables are a classic strategy in computer science to speed calculations. The basic idea is to replace a runtime calculation (which can take a long time to be done) by a basic array indexing operation.\nInstead of calculating the results everytime you need them, you calculate all possible results at once, and then, you store them in an array (which behaves lake a “table”). Then, every time that you need to use one of the characters in the base64 scale, instead of using many resources to calculate the exact character to be used, you simply retrieve this character from the array where you stored all the possible characters in the base64 scale. So we retrieve the character that we need directly from memory.\nWe can start building a Zig struct to store our base64 decoder/encoder logic. We start with the Base64 struct below. You can see that, for now, we only have an init() function, to create a new instance of a Base64 object, and, a _char_at() function, which is a “get chat at index …” type of function.\n\nconst Base64 = struct {\n    _table: *const [64]u8,\n\n    pub fn init() Base64 {\n        const upper = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\";\n        const lower = \"abcdefghijklmnopqrstuvwxyz\";\n        const numbers_symb = \"0123456789+/\";\n        return Base64{\n            ._table = upper ++ lower ++ numbers_symb,\n        };\n    }\n\n    pub fn _char_at(self: Base64, index: u8) u8 {\n        return self._table[index];\n    }\n};\n\nIn other words, the _char_at() function is responsible for getting the character in the lookup table (i.e. the _table variable) that corresponds to a particular index in the “base64 scale”. So, in the example below, we know that the character that corresponds to the index 28 in the “base64 scale” is the character “c”.\n\nconst base64 = Base64.init();\ntry stdout.print(\n    \"Character at 28 index: {c}\\n\",\n    .{base64._char_at(28)}\n);\n\nCharacter at 28 index: c\n\n\n2.1.3 A base64 encoder\nThe algorithm behind a base64 encoder usually works on a window of 3 bytes. Because each byte have 8 bits, so, 3 bytes forms a set of \\(8 \\times 3 = 24\\) bits. This is desirable for the base64 algorithm, because 24 bits is divisble by 6, which form a set of 4 groups of 6 bits each.\nSo the base64 algorithm work by converting 3 bytes at a time into 4 characters in the base64 scale. It keeps iterating through the input string, 3 bytes at a time, and converting them into the base64 scale, producing 4 characters per iteration. It keeps iterating, and producing these “new characters” until it hits the end of the input string.\nNow you may think, what if you have a particular string that have a number of bytes that is not divisible by 3? What happens? For example, if you have a string that contains only two characters/bytes, such as “Hi”. How the algorithm behaves in such situation? You find the answer at Figure 2.1. You can see at Figure 2.1 that the string “Hi”, when converted to base64, becomes the string “SGk=”:\n\n\n\n\n\n\nFigure 2.1: The logic behind a base64 encoder\n\n\n\nIn the example of the string “Hi” we have 2 bytes, or, 16 bits in total. So, we lack a full byte (8 bits) to complete the window of 24 bits that the base64 algorithm likes to work on. In essence, everytime that the algorithm does not meet this requirement, it simply add extra zeros until it fills the space that it needs.\nThat is why at Figure 2.1, on the third group after the 6-bit transformation, 2 extra zeros were added to fill the gap in this group, and also, the fourth group (which is the last 6-bit group) after the 6-bit transformation is entirely made by zeros that were added by the algorithm.\nSo every time that the base64 algorithm can’t produce a full group of 6 bits, it simply fills the gap in this group with zeros, until it get’s the 6 bits that it needs.\nIs worth mentioning that, everytime that the algorithm produces a group of 6 bits that is entirely composed by zeros, this group of 6 bits is automatically mapped to the character = (equal sign). In other works, the group 000000 is translated into the character =. Because it represents the end of meaningful characters in the sequence.\n\n\n2.1.4 A base64 decoder\nThe algorithm behind a base64 decoder is essentially the inverse process of a base64 encoder. A base64 decoder needs to be able to translate base64 messages back into their original meaning, i.e. into the original sequence of binary data.\nA base64 decoder usually works on a window of 4 bytes. Because it wants to convert these 4 bytes back into the original sequence of 3 bytes, that was converted into 4 groups of 6 bits by the base64 encoder. Remember, in a base64 decoder we are essentially reverting the process made by the base64 encoder.\nEach byte in the input string (the base64 encoded string) normally contributes to re-create two different bytes in the output (the original binary data). In other words, each byte that comes out of a base64 decoder is created by transforming merging two different bytes in the input together. You can see this fact at Figure 2.2:\n\n\n\n\n\n\nFigure 2.2: The logic behind a base64 decoder\n\n\n\nThe exact transformations, or, the exact steps applied to each byte from the input to transform them into the bytes in the output, are a bit tricky to visualize in a figure like this. Because of that, I summarized these transformations as “Some bit shifting and additions …”. These transformations will be described in depth later.\nBesides that, if you look again at Figure 2.2, you will notice that the character = was completly ignored in the algorithm. Remember, this is just a special character that marks the end of meaninful characters in the base64 sequence. So, every = character in a base64 encoded sequence should be ignored.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Building a base64 encoder/decoder</span>"
    ]
  },
  {
    "objectID": "Chapters/01-base64.html#sec-encode-vs-decode",
    "href": "Chapters/01-base64.html#sec-encode-vs-decode",
    "title": "2  Building a base64 encoder/decoder",
    "section": "2.2 Difference between encode and decode",
    "text": "2.2 Difference between encode and decode\nIf you don’t have any previous experience with base64, you might be confused about what is the differente between “encode” and “decode”. Essentially, the terms “encode” and “decode” here have the exact same meaning as they have in the field of encryption (i.e. they mean the same thing as “encode” and “decode” in hashing algorithms, like the MD5 algorithm).\nSo, “encode” means that we want to encode, or, in other words, we want to translate some message into the base64 encoding system. We want to produce the sequence of base64 characters that represent this original message in the base64 encoding system.\nIn contrast, “decode” represents the inverse process. We want to decode, or, in other words, translate a base64 message back to it’s original content. So, in this process we get a sequence of base64 characters as input, and produce as output, the binary data that is represented by this sequence of base64 characters.\nSo, any base64 library is normally composed by these two parts: 1) the encoder, which is a function that encodes (i.e. it converts) any sequence of binary data into a sequence of base64 characters; 2) the decoder, which is a function that converts a sequence of base64 characters back into the original sequence of binary data.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Building a base64 encoder/decoder</span>"
    ]
  },
  {
    "objectID": "Chapters/01-base64.html#calculating-the-size-of-the-output",
    "href": "Chapters/01-base64.html#calculating-the-size-of-the-output",
    "title": "2  Building a base64 encoder/decoder",
    "section": "2.3 Calculating the size of the output",
    "text": "2.3 Calculating the size of the output\nOne task that we need to do is to calculate how much space we need to reserve for the output, both of the encoder and decoder. This is simple math, and can be done easily in Zig because every array have it’s length (it’s number of bytes) easily accesible by consulting the .len property of the array.\nFor the encoder, the logic is the following: for each 3 bytes that we find in the input, 4 new bytes are created in the output. So, we take the number of bytes in the input, divide it by 3, use a ceiling function, then, we multiply the result by 4. That way, we get the total number of bytes that will be produced by the encoder in it’s output.\nThe _calc_encode_length() function below encapsulates this logic. Notice that we convert the .len property of the array, which is always a integer (more precisely, an usize value), into a floating point number of 64 bits (f64). We do this, because the ceiling function (@ceil()) works only with floating point numbers. So, we convert it so that the division with the number 3.0 results in a floating point number. Then, after the ceiling process, we can convert the result back into an integer value (with the @intFromFloat() function).\n\nfn _calc_encode_length(input: []const u8) u64 {\n    if (input.len &lt; 3) {\n        const n_output: u64 = 4;\n        return n_output;\n    }\n    const len_as_float: f64 = @floatFromInt(input.len);\n    const n_output: u64 = @intFromFloat(@ceil(len_as_float / 3.0) * 4.0);\n    return n_output;\n}\n\nIs important to notice that, when I am using the built-in functions from Zig to convert data types (@floatFromInt() and intFromFloat()), I’m always annotating explicitly the type of the variable that stores the result of these functions. I do that, because these functions need this information. @floatFromInt() needs to know which type of floating point number I want to use in it’s output. Is it f16? f32? f64? etc. The same goes to @intFromFloat().\nAlso, you might have notice that, if the input length is less than 3 bytes, then, the output length of the encoder will be always 4 bytes. This is because the algorithm will always fill the gap in the input with zeroes, until it fits the window of 24 bits that the algorithm likes to work on, as I described at Section 2.1.3. So the output of the algorithm will always be 4 bytes in this specific case.\nNow, for the decoder, we just need to apply the inverse logic: for each 4 bytes in the input, 3 bytes will be produced in the output of the decoder. I mean, this is roughly true, because we also need to take the = character into account, which is always ignored by the decoder, as we described at Section 2.1.4, and, at Figure 2.2. But we can ignore this fact for now, to make things simpler.\nSo, the function _calc_decode_length() summarizes this logic that we described. It is very similar to the function _calc_encode_length(), only the division part is twisted, and also, in the special case where we have less than 4 bytes in the input to work on.\n\nfn _calc_decode_length(input: []const u8) u64 {\n    if (input.len &lt; 4) {\n        const n_output: u64 = 3;\n        return n_output;\n    }\n    const len_as_float: f64 = @floatFromInt(input.len);\n    const n_output: u64 = @intFromFloat(@floor(len_as_float / 4.0) * 3.0);\n    return n_output;\n}",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Building a base64 encoder/decoder</span>"
    ]
  },
  {
    "objectID": "Chapters/01-base64.html#building-the-encoder-logic",
    "href": "Chapters/01-base64.html#building-the-encoder-logic",
    "title": "2  Building a base64 encoder/decoder",
    "section": "2.4 Building the encoder logic",
    "text": "2.4 Building the encoder logic\nIn this section, we can start building the logic behind the encode() function, which will be responsible for encoding messages into the base64 encoding system.\n\n2.4.1 Quick & dirty approach for the two bytes case\nTo get a better understanding of what we need to do, let’s implement just the bare minimum necessary to convert the string “Hi” into the base64 encoding system. It doesn’t need to be preety or good quality code. It just needs to work.\nRemember that the string “Hi” is not the perfect case for the base64 algorithm. Because it is two bytes long, and the algorithm likes to work on a sequence of 3 bytes. But we can still use this case as our starting point. After that, we go up on the ladder, until we reach the ideal scenario.\n\n2.4.1.1 The 6-bit transformation\nThe core part of the algorithm is the 6-bit transformation that was presented at Figure 2.1. By understanding how this transformation is made in code, the rest of the algorithm becomes much simpler to comprehend.\nIn essence, this 6-bit transformation is made with the help of bitwise operators. Bitwise operators are essential to any type of low-level operation that is done at the bit-level. For the specific case of the base64 algorithm, the operators bif shift to left (&lt;&lt;) and bit shift to the right (&gt;&gt;) are used. They are the core solution for the 6-bit transformation.\n\nQuick recap: the first byte of the input string (“H”) is, in binary, the sequence 01001000, while the second byte (“i”), is the sequence 01101001. Just have these sequences in mind.\n\nLet’s begin by building the first byte in the ouput. Because it is the easiest of all to build, since we only need to extract the first 6-bits from the first byte of the input (01001000). To that we can use bit shifting.\nWe begin by creating the variable text, which contains the string that we want to convert/encode (“Hi”). We also set a buffer variable called output, which will contain the output of the encoding process at the end. Since the string “Hi” is only two bytes long, as I described in the previous section, we need an array of 4 bytes to hold the output of the encoding process.\n\npub fn main() !void {\n    const text = \"Hi\";\n    _ = text;\n    const output = [4]u8{0,0,0,0};\n    _ = output;\n}\n\n\n\n\n2.4.2 Encapsulating this logic into a function\n\nfn encode(self: Base64,\n          input: []const u8,\n          allocator: std.mem.Allocator) ![]u8 {\n\n    if (input.len == 0)\n    return \"\";\n\n    const n_out = _calc_encode_length(input);\n    var out = try allocator.alloc(u8, n_out);\n    var buf = [3]u8{ 0, 0, 0 };\n    var count: u8 = 0;\n    var iout: u64 = 0;\n\n    for (input, 0..) |_, i| {\n        buf[count] = input[i];\n        count += 1;\n        if (count == 3) {\n            out[iout] = self._char_at(buf[0] &gt;&gt; 2);\n            out[iout + 1] = self._char_at(\n                ((buf[0] & 0x03) &lt;&lt; 4) + (buf[1] &gt;&gt; 4)\n            );\n            out[iout + 2] = self._char_at(\n                ((buf[1] & 0x0f) &lt;&lt; 2) + (buf[2] &gt;&gt; 6)\n            );\n            out[iout + 3] = self._char_at(buf[2] & 0x3f);\n            iout += 4;\n            count = 0;\n        }\n    }\n\n    if (count == 1) {\n        out[iout] = self._char_at(buf[0] &gt;&gt; 2);\n        out[iout + 1] = self._char_at(\n            (buf[0] & 0x03) &lt;&lt; 4\n        );\n        out[iout + 2] = '=';\n        out[iout + 3] = '=';\n    }\n\n    if (count == 2) {\n        out[iout] = self._char_at(buf[0] &gt;&gt; 2);\n        out[iout + 1] = self._char_at(\n            ((buf[0] & 0x03) &lt;&lt; 4) + (buf[1] &gt;&gt; 4)\n        );\n        out[iout + 2] = self._char_at(\n            (buf[1] & 0x0f) &lt;&lt; 2\n        );\n        out[iout + 3] = '=';\n        iout += 4;\n    }\n\n    return out;\n}",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Building a base64 encoder/decoder</span>"
    ]
  }
]